{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "UuTCgre3Gpxm",
    "outputId": "de69958e-1422-4c74-bcd6-7dd7d44bc1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
      "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "!pip install librosa\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-upI18AoG4Yg"
   },
   "outputs": [],
   "source": [
    "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
    "S_sgn=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "# librosa phase - maxphase\n",
    "\n",
    "# print(phase.shape)\n",
    "# output * phase\n",
    "# istft\n",
    "\n",
    "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
    "X_sgn=librosa.stft(sn, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em-BgtPXHD7w"
   },
   "outputs": [],
   "source": [
    "\n",
    "S_sgn = np.abs(S_sgn.T)\n",
    "S_sgn = S_sgn\n",
    "X_sgn_abs = np.abs(X_sgn.T)\n",
    "X_sgn_abs = X_sgn_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NksGamsuyM7x"
   },
   "source": [
    "** Padding silent frames **\n",
    "* To make the input data compatible with labels we need to pad 19 silent frames to the input in the beginning.\n",
    "* As each input cnn image is $20*513$ to have 2459 output values we need to pad this input with random numbers closer to the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QRZjEl07i3_4",
    "outputId": "853a8409-3f8f-4620-bb73-7576f781cf83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2478, 513)\n"
     ]
    }
   ],
   "source": [
    "def pad_silent(x):\n",
    "  pad = np.empty([19,513])\n",
    "  for i in range(0,19):\n",
    "    pad[i,:] = np.random.rand(1,513)/1000\n",
    "  y = np.concatenate((pad, x))\n",
    "  return y\n",
    "\n",
    "X_sgn = pad_silent(X_sgn_abs)\n",
    "\n",
    "print(X_sgn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_JZTSrEp-1o"
   },
   "source": [
    "**2-D CNN  structure**\n",
    "\n",
    "\n",
    "*   For Audio cleaning problem a 2-d convolutional neural network is built with the following:\n",
    "* Input is 513 shape vector \n",
    "* 2 convolutional layers:\n",
    "  - One with 16 filters, filter size of (3,3)\n",
    "  - One with 32 filters, filter size of (3,3)\n",
    "* Each convolution layer is followed by a max-pooling layer with pooling size (2,2) and stride taken as 2 units.\n",
    "* 1 dense fully connected layer with 2048 and Relu as activation function\n",
    "* Dropout of 0.4 on dense layer\n",
    "* Logits layer to output with 513 neurons to match output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yJHSr36mQax"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "\n",
    "n_input = 513\n",
    "n_dense = 2048\n",
    "n_output = 513  \n",
    "n_height = 20\n",
    "filter1 = 16\n",
    "kernel_size1 = 3\n",
    "filter2 = 32\n",
    "kernel_size2 = 3\n",
    "drop_out = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "e4dRVeLCUqkY",
    "outputId": "d4a88a0c-81e3-4e19-a0bb-f7519f3c42d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 128, 32)\n",
      "(?, 513)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_height, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "\n",
    "X1 = tf.reshape(X, [-1, n_height, n_input, 1])\n",
    "Y1 = tf.reshape(Y, [-1, n_height, n_output, 1])\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=X1,\n",
    "    filters=filter1,\n",
    "    kernel_size=(kernel_size1,kernel_size1),\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=(2,2), strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=filter2,\n",
    "    kernel_size=(kernel_size2,kernel_size2),\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=(2,2), strides=2)\n",
    "print(pool2.shape)\n",
    "# Dense Layer\n",
    "pool2_flat = tf.reshape(pool2, [-1, 5 * 128 * filter2])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=n_dense, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=drop_out)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout, units=n_output)\n",
    "print(logits.shape)\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\n",
    "loss=tf.losses.mean_squared_error(labels=tf.reshape(Y1, [-1, n_output]), predictions=logits)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "# print(logits)\n",
    "\n",
    "# print(S_sgn)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y1, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzkQHERw90BJ"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "sess.run(init_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25ByYvTQyyvO"
   },
   "source": [
    "** Data parsing for cnn input **\n",
    "* With $2459*513$ input we need to form 2459 frames of each $20*513*.\n",
    "* This is achieved using th emethod below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R-q48aX6PKf8",
    "outputId": "9d1ec9fd-1e5b-4ca6-84ad-9b28f4bc2053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 20, 513) (2459, 513)\n"
     ]
    }
   ],
   "source": [
    "def split_2d(data):\n",
    "  input_data = [np.array(data[i:i+20,:]) for i in range(0,len(data)-19)]\n",
    "  return np.array(input_data)\n",
    "\n",
    "x = split_2d(X_sgn)\n",
    "y = S_sgn\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6yOeGnwyxu3"
   },
   "source": [
    "** Mini Batching **\n",
    "\n",
    "* For mini batches, the input is randomly sampled.\n",
    "* A batch that is based on the batch size given is taken from the input at a random position.\n",
    "* Each batch and corresponding labels are fed to the training model at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afPvo_hH92NX"
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "  idx = random.randint(0,19)\n",
    "  batch_x = x[idx*batch_size:idx*batch_size + batch_size]\n",
    "  batch_y = y[idx*batch_size:idx*batch_size + batch_size,:]\n",
    "  sess.run(train_step, feed_dict={X: batch_x, Y: batch_y})\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGcos9Hj_L-m"
   },
   "outputs": [],
   "source": [
    "# Method to refine test audio files\n",
    "def process_test(file, out):\n",
    "\n",
    "  test, sr = librosa.load(file, sr=None)\n",
    "  test_sgn = librosa.stft(test, n_fft=1024, hop_length=512)\n",
    "  magnitude, phase = librosa.magphase(test_sgn)\n",
    "  test_s = np.abs(test_sgn)\n",
    "  pad_test_s = pad_silent(test_s.T)\n",
    "  pred = sess.run(logits, feed_dict={X: split_2d(pad_test_s)})\n",
    "  pred = np.multiply(np.divide(test_sgn,test_s),pred.T)\n",
    "  sh_test = librosa.istft(pred, hop_length=512)\n",
    "  if(out == 1):\n",
    "    outfile = 'test_s_01_recons.wav'\n",
    "  else:\n",
    "    outfile = 'test_s_02_recons.wav'\n",
    "  librosa.output.write_wav(outfile, sh_test, sr)\n",
    "  \n",
    "  \n",
    "def snr(signal, est):\n",
    "  num = np.sum(np.square(signal))\n",
    "  den = np.sum(np.square(signal-est))\n",
    "  snr = 10* np.log10(num/den)\n",
    "  return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFTFmlxTeJgQ"
   },
   "outputs": [],
   "source": [
    "def process_train(file):\n",
    "\n",
    "  test, sr = librosa.load(file, sr=None)\n",
    "  test_sgn = librosa.stft(test, n_fft=1024, hop_length=512)\n",
    "  magnitude, phase = librosa.magphase(test_sgn)\n",
    "  test_s = np.abs(test_sgn)\n",
    "  pad_test_s = pad_silent(test_s.T)\n",
    "  pred = sess.run(logits, feed_dict={X: split_2d(pad_test_s)})\n",
    "  pred = np.multiply(np.divide(test_sgn,test_s),pred.T)\n",
    "  sh_test = librosa.istft(pred, hop_length=512, length=len(test))\n",
    "  \n",
    "  s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
    "  print(snr(s, sh_test))\n",
    "  outfile = 'train_s_recons.wav'\n",
    "  librosa.output.write_wav(outfile, sh_test, sr)\n",
    "  return snr(s, sh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LZOabnKs_OXP",
    "outputId": "b97866f1-612c-4675-cffe-bdb9e9271036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR for train file :\n",
      "13.343751430511475\n"
     ]
    }
   ],
   "source": [
    "# process_test('test_x_01.wav',1)\n",
    "# process_test('test_x_02.wav',2)\n",
    "print(\"SNR for train file :\")\n",
    "snr = process_train('train_dirty_male.wav')\n",
    "\n",
    "# print(snr(test_sgn_ab, test_ns_ab)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSYBZkiyuhC7"
   },
   "outputs": [],
   "source": [
    "with open(\"performance.txt\", \"a\") as text_file:\n",
    "    print(f\"CNN 2\", file=text_file)\n",
    "    print(f\"SNR: {snr}\", file=text_file)\n",
    "    print(f\"LR: {lr}\\t Iterations: {n_iterations}\\t Batch Size: {batch_size}\", file=text_file)\n",
    "    print(f\"Filter1: {filter1}\\t Kernel1: {kernel_size1,kernel_size1}\", file=text_file)\n",
    "    print(f\"Filter2: {filter2}\\t Kernel2: {kernel_size2,kernel_size2}\", file=text_file)\n",
    "    print(f\"Dense neurons: {n_dense}\\t Drop Out: {drop_out}\\n\",file= text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4Rrs00tzOy9"
   },
   "source": [
    "** Result **\n",
    "* With given parameters for 1-d CNN the SNR for train file is 13.34. \\\n",
    "**SNR**: **13.343751430511475** \\\n",
    "**Learning Rate**: 0.001\t **Iterations**: 1000\t\\\n",
    "**Batch Size**: 128 \\\n",
    "**Filter1**: 16\t **Kernel1**: 3 \\\n",
    "**Filter2**: 32\t **Kernel2**: 3 \\\n",
    "**Dense neurons**: 2048\t \\\n",
    "Drop out: 0.4\n",
    "* The output files generated for test audio samples seem reasonable with less noise of chips but the performance did not seem as good as that of fully connected layer as far as audio is concerned."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_HW2_Q2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
