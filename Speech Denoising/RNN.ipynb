{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW3_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdDV60Tlhb_",
        "colab_type": "code",
        "outputId": "b104d328-854b-4392-c3a1-1a2d351b867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pickle\n",
        "import wave, os, glob\n",
        "import librosa\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65c3oKoctApR",
        "colab_type": "text"
      },
      "source": [
        "**Reading Data**\n",
        "- With three sets of data (clean, noise, dirty) each 1200 signal files, they are taken into 3 separate entities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1HbHltI7E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "zero = []\n",
        "path = '/content/drive/My Drive/dl_timit/tr'\n",
        "i = 0\n",
        "tr_X = []\n",
        "tr_S = []\n",
        "tr_N = []\n",
        "for filename in sorted(glob.glob(os.path.join(path, '*.wav'))):\n",
        "  s, sr=librosa.load(filename, sr=None)\n",
        "  S_sgn=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "  S_sgn = np.abs(S_sgn).T\n",
        "  if(i<1200):\n",
        "    tr_N.append(S_sgn)\n",
        "  elif (i<2400):\n",
        "    tr_S.append(S_sgn)\n",
        "  else:\n",
        "    tr_X.append(S_sgn)\n",
        "  i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gerzs_pxtRlx",
        "colab_type": "text"
      },
      "source": [
        "**Dumping the data into drive using pickle for future usage.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APIFEi-buCHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/dl_timit/trs.pkl', 'wb') as f:\n",
        "  pickle.dump(tr_S, f)\n",
        "\n",
        "with open('/content/drive/My Drive/dl_timit/trx.pkl', 'wb') as f:\n",
        "  pickle.dump(tr_X, f)\n",
        "\n",
        "with open('/content/drive/My Drive/dl_timit/trn.pkl', 'wb') as f:\n",
        "  pickle.dump(tr_N, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdXSjNKVtaHR",
        "colab_type": "text"
      },
      "source": [
        "**Loading data from pickle dumps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8nkk3l7ugUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/dl_timit/trs.pkl', 'rb') as f:\n",
        "    tr_S = pickle.load(f)\n",
        "with open('/content/drive/My Drive/dl_timit/trx.pkl', 'rb') as f:\n",
        "    tr_X = pickle.load(f)\n",
        "with open('/content/drive/My Drive/dl_timit/trn.pkl', 'rb') as f:\n",
        "    tr_N = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD__yUWj3xtw",
        "colab_type": "code",
        "outputId": "43298b4c-362e-4d4b-ead1-ac96bbcc5a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tr_S[0].shape, tr_X[0].shape, tr_N[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65, 513) (65, 513) (65, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC_ujuMctduL",
        "colab_type": "text"
      },
      "source": [
        "**Building Masked target matrices for each of the signal.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hyglFdq25S",
        "colab_type": "code",
        "outputId": "10c26f2b-1577-4480-8daf-c4d75c0a3faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tr_X), len(tr_S), len(tr_N))\n",
        "\n",
        "def build_ibm(s,n):\n",
        "  return (s>n)*1\n",
        "\n",
        "def build_target(tr_X, tr_S, tr_N): \n",
        "  ibm_target = []\n",
        "  for idx,x in enumerate(tr_X):\n",
        "    ibm_target.append(build_ibm(tr_S[idx], tr_N[idx]))\n",
        "  return ibm_target\n",
        "\n",
        "ibm_target = build_target(tr_X, tr_S, tr_N)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200 1200 1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWK5KlW-P0yz",
        "colab_type": "code",
        "outputId": "97f42891-88ab-47ba-aff2-8ec6b3ce2a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print((ibm_target[0].shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBOB1IDbtlAL",
        "colab_type": "text"
      },
      "source": [
        "# RNN network using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-QBYxS_v2dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "X = tf.placeholder(tf.float32, shape=(None, None, 513))\n",
        "y_actual = tf.placeholder(tf.float32, shape=(None, None, 513))\n",
        "dropout = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKL4K6Xuv5g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = []\n",
        "layer = tf.contrib.rnn.LSTMCell(513, forget_bias=1.0)\n",
        "layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout)\n",
        "layers.append(layer)\n",
        "layer = tf.contrib.rnn.LSTMCell(513, forget_bias=1.0)\n",
        "layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout)\n",
        "layers.append(layer)\n",
        "layer = tf.contrib.rnn.MultiRNNCell(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_TUWdbzv8UF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out, _ = tf.nn.dynamic_rnn(layer, X, dtype=tf.float32)\n",
        "logits = tf.contrib.layers.fully_connected(out, 513, activation_fn=tf.nn.sigmoid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjCfCOzdv97m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss=tf.losses.mean_squared_error(labels=y_actual, predictions=logits)\n",
        "\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgQYPTr6v_k-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "saver=tf.train.Saver()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO_AwymbtpaC",
        "colab_type": "text"
      },
      "source": [
        "# Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wftut4UwBt2",
        "colab_type": "code",
        "outputId": "a5134111-f468-4b39-fd58-5cc281de0d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "batch_size = 10\n",
        "for epoch in range(15):\n",
        "  loss_print = 0\n",
        "  #print(epoch)\n",
        "  for i in range(0, 1200, batch_size):\n",
        "    batch = []\n",
        "    for j in range(i,i+batch_size,1):\n",
        "      batch.append(np.greater(tr_S[j],tr_N[j])*1)\n",
        "    batch = np.asarray(batch)\n",
        "    batch_data = np.array(tr_X[i:i+batch_size])\n",
        "    loss1, _ = sess.run([loss, train_step], {X: batch_data, y_actual: batch, dropout: 0.5})\n",
        "\n",
        "    loss_print += loss1\n",
        "  print('Loss at epoch',epoch+1, 'is: ', loss_print)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 1 is:  26.070965453982353\n",
            "Loss at epoch 2 is:  22.789561435580254\n",
            "Loss at epoch 3 is:  20.784970581531525\n",
            "Loss at epoch 4 is:  19.476837322115898\n",
            "Loss at epoch 5 is:  18.585249550640583\n",
            "Loss at epoch 6 is:  17.952603690326214\n",
            "Loss at epoch 7 is:  17.509383261203766\n",
            "Loss at epoch 8 is:  17.127324551343918\n",
            "Loss at epoch 9 is:  16.90227361023426\n",
            "Loss at epoch 10 is:  16.60350976884365\n",
            "Loss at epoch 11 is:  16.36005086451769\n",
            "Loss at epoch 12 is:  16.253773376345634\n",
            "Loss at epoch 13 is:  16.013659089803696\n",
            "Loss at epoch 14 is:  15.803144827485085\n",
            "Loss at epoch 15 is:  15.651528671383858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH3aDj3FtsPq",
        "colab_type": "text"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWfhr9Rq2ZCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/dl_timit/trs_val.pkl', 'rb') as f:\n",
        "    trS_val = pickle.load(f)\n",
        "# with open('/content/drive/My Drive/dl_timit/trx_val.pkl', 'rb') as f:\n",
        "#     trX_val = pickle.load(f)\n",
        "# with open('/content/drive/My Drive/dl_timit/trn_val.pkl', 'rb') as f:\n",
        "#     trN_val = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whlnPKlO2S6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trX_val_pred = []\n",
        "# for i in range(1200):\n",
        "#   rows = trX_val[i].shape[0]\n",
        "#   M_ =  sess.run(logits, {X: trX_val[i].reshape(-1, rows, 513), dropout:0.5})\n",
        "#   M_ = np.multiply(M_, trX_val[i])\n",
        "#   M_ = M_.reshape(rows, 513)\n",
        "#   S_ = librosa.istft(M_, hop_length = 512)\n",
        "#   #print(S_.shape)\n",
        "# #   librosa.output.write_wav(('val_output_'+str(i)+'.wav'), S_, sr = 100000)\n",
        "#   trX_val_pred.append(S_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5H8AQDa28YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def snr(inp, out):\n",
        "  num = np.sum(np.square(inp))\n",
        "  den = np.sum(np.square(inp-out))\n",
        "  snr = 10* np.log10(num/den)\n",
        "  return snr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLVYkbKEq3xi",
        "colab_type": "text"
      },
      "source": [
        "**Validation**\n",
        "\n",
        "- Now with the trained model, we can check the validation dataset and check for SNR.\n",
        "- Here with 1200 validation files (noise, clean, dirty), the output signal is predicted from the model and SNR is calculated.\n",
        "**Validation SNR value : 14.048**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJy7qKB-dl1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_valid_snr(file, s_clean):\n",
        "  s, sr=librosa.load(file, sr=None)\n",
        "  S_sgn=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "  val_sgn = np.abs(S_sgn).T\n",
        "  rows = val_sgn.shape[0]\n",
        "  M_ =  sess.run(logits, {X: val_sgn.reshape(-1, rows, 513), dropout:0.5})\n",
        "  M_ = np.multiply(M_, val_sgn)\n",
        "  M_ = M_.reshape(rows, 513)\n",
        "  pred = np.multiply(np.divide(S_sgn,np.abs(S_sgn)),M_.T)\n",
        "  S_ = librosa.istft(pred, hop_length = 512, length=len(s))\n",
        "  #print(S_.shape)\n",
        "  return snr(s_clean, S_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muacl9XH2_B-",
        "colab_type": "code",
        "outputId": "9d404a01-8fad-42f1-ee8f-f11d5068987f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "snr_val = 0\n",
        "# for i in range(1200):\n",
        "#   trS_val_i =librosa.istft(trS_val[i],hop_length = 512)\n",
        "#   #print(clean_val[i].shape)\n",
        "#   #print(clean_predicted_val[i].shape)\n",
        "#   snr_val += snr(trS_val_i, trX_val_pred[i])\n",
        "# print(snr_val/1200)\n",
        "# snr_val_i = 0\n",
        "val_path = '/content/drive/My Drive/dl_timit/v'\n",
        "j = 0\n",
        "for filename in sorted(glob.glob('/content/drive/My Drive/dl_timit/v/vx*')):\n",
        "  snr_val_i = process_valid_snr(filename, trS_val[j])\n",
        "  snr_val += snr_val_i\n",
        "  j += 1\n",
        "\n",
        "print(snr_val/1200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.225396546969811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-qCeqAytwJh",
        "colab_type": "text"
      },
      "source": [
        "# Test Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIduBC2FONyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_test(file, outpath):\n",
        "  s, sr=librosa.load(file, sr=None)\n",
        "  S_sgn=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "  test_sgn = np.abs(S_sgn).T\n",
        "  rows = test_sgn.shape[0]\n",
        "  M_ =  sess.run(logits, {X: test_sgn.reshape(-1, rows, 513), dropout:0.5})\n",
        "  M_ = np.multiply(M_, test_sgn)\n",
        "  M_ = M_.reshape(rows, 513)\n",
        "  pred = np.multiply(np.divide(S_sgn,np.abs(S_sgn)),M_.T)\n",
        "  S_ = librosa.istft(pred, hop_length = 512, length=len(s))\n",
        "  #print(S_.shape)\n",
        "  file = os.path.split(file)[1]\n",
        "  outfile = os.path.join(outpath, file)\n",
        "  print(outfile)\n",
        "  librosa.output.write_wav(outfile, S_, sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjQUWcEARNyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/dl_timit/te'\n",
        "outpath = '/content/drive/My Drive/dl_timit/test_out'\n",
        "i = 0\n",
        "for filename in sorted(glob.glob(os.path.join(path, '*.wav'))):\n",
        "  process_test(filename, outpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPcLFATs8Ax",
        "colab_type": "text"
      },
      "source": [
        "**Output signals for all the test data is stored into a folder.**"
      ]
    }
  ]
}
