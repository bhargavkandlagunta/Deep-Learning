{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "UuTCgre3Gpxm",
    "outputId": "c3b55e8e-338e-40a2-8615-206ac459b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
      "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "!pip install librosa\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-upI18AoG4Yg"
   },
   "outputs": [],
   "source": [
    "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
    "S_sgn=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "\n",
    "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
    "X_sgn=librosa.stft(sn, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Em-BgtPXHD7w",
    "outputId": "c536367e-4e56-4007-a533-8b439a372bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 513)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "S_sgn = np.abs(S_sgn.T)\n",
    "S_sgn = S_sgn\n",
    "X_sgn = np.abs(X_sgn.T)\n",
    "X_sgn = X_sgn\n",
    "print(X_sgn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ln1nTEZ0UIYV"
   },
   "source": [
    "**1-D CNN  structure**\n",
    "\n",
    "\n",
    "*   For Audio cleaning problem a 1-d convolutional neural network is built with the following:\n",
    "* Input is 513 shape vector \n",
    "* 2 convolutional layers:\n",
    "  - One with 32 filters, filter size of (3,3)\n",
    "  - One with 64 filters, filter size of (2,2)\n",
    "* Each convolution layer is followed by a max-pooling layer with pooling size (2,2) and stride taken as 2 units.\n",
    "* 1 dense fully connected layer with 2048 and Relu as activation function\n",
    "* Dropout of 0.4 on dense layer\n",
    "* Logits layer to output with 513 neurons to match output shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yJHSr36mQax"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "dropout = 0.5\n",
    "\n",
    "n_input = 513   # input layer (28x28 pixels)\n",
    "n_dense = 2048\n",
    "n_output = 513 \n",
    "filter1 = 32\n",
    "kernel_size1 = 3\n",
    "filter2 = 64\n",
    "kernel_size2 = 2\n",
    "drop_out = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4dRVeLCUqkY"
   },
   "outputs": [],
   "source": [
    "# def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "# X = tf.reshape(X_sgn, [-1, 512, 1])\n",
    "# Y = tf.reshape(S_sgn, [-1, 512, 1])\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "\n",
    "X1 = tf.reshape(X, [-1, n_input, 1])\n",
    "Y1 = tf.reshape(Y, [-1, n_output, 1])\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv1d(\n",
    "    inputs=X1,\n",
    "    filters=filter1,\n",
    "    kernel_size=(kernel_size1),\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=[2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv1d(\n",
    "    inputs=pool1,\n",
    "    filters=filter2,\n",
    "    kernel_size=(kernel_size2),\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=[2], strides=2)\n",
    "print(pool2.shape)\n",
    "# Dense Layer\n",
    "pool2_flat = tf.reshape(pool2, [-1, 128 * filter2])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=n_dense, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense, rate=drop_out)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dense, units=n_output)\n",
    "print(logits.shape)\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\n",
    "loss=tf.losses.mean_squared_error(labels=tf.reshape(Y1, [-1, n_output]), predictions=logits)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "# print(logits)\n",
    "\n",
    "# print(S_sgn)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y1, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzkQHERw90BJ"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxXk82iPlngn"
   },
   "source": [
    "** Mini Batching **\n",
    "* For mini batches, the input is randomly sampled.\n",
    "* A batch that is based on the batch size given is taken from the input at a random position.\n",
    "* Each batch and corresponding labels are fed to the training model at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afPvo_hH92NX"
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "  idx = random.randint(0,20)\n",
    "  batch_x = X_sgn[idx*batch_size:idx*batch_size + batch_size,:]\n",
    "  batch_y = S_sgn[idx*batch_size:idx*batch_size + batch_size,:]\n",
    "  sess.run(train_step, feed_dict={X: batch_x, Y: batch_y})\n",
    "#   sess.run(train_step, feed_dict={X: X_sgn[0,:], Y: S_sgn[0,:]})\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDkuWG6xmlP5"
   },
   "source": [
    "** Testing **\n",
    "* Method to process test files and create out put .wav files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGcos9Hj_L-m"
   },
   "outputs": [],
   "source": [
    "# Method to refine test audio files\n",
    "def process_test(file, out):\n",
    "\n",
    "  test, sr = librosa.load(file, sr=None)\n",
    "  test_sgn = librosa.stft(test, n_fft=1024, hop_length=512)\n",
    "  print(test_sgn.shape)\n",
    "  magnitude, phase = librosa.magphase(test_sgn)\n",
    "  test_s = np.abs(test_sgn)\n",
    "\n",
    "  pred = sess.run(logits, feed_dict={X: test_s.T})\n",
    "  pred = np.multiply(np.divide(test_sgn,test_s),pred.T)\n",
    "#   print(pred.shape)\n",
    "  sh_test = librosa.istft(pred, hop_length=512, length=len(test))\n",
    "#   print(\"SNR :\")\n",
    "#   print(sh_test.shape)\n",
    "#   print(snr(test, sh_test))\n",
    "  if(out == 1):\n",
    "    outfile = 'test_s_01_recons.wav'\n",
    "  else:\n",
    "    outfile = 'test_s_02_recons.wav'\n",
    "  librosa.output.write_wav(outfile, sh_test, sr)\n",
    "  \n",
    "  \n",
    "def snr(signal, est):\n",
    "  num = np.sum(np.square(signal))\n",
    "  den = np.sum(np.square(signal-est))\n",
    "  snr = 10* np.log10(num/den)\n",
    "  return snr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VZaKdTGmwp7"
   },
   "source": [
    "** SNR **\n",
    "* Method to process train file get predictions and find SNR to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbTC6IjhsRis"
   },
   "outputs": [],
   "source": [
    "def process_train(file, out):\n",
    "\n",
    "  test, sr = librosa.load(file, sr=None)\n",
    "  test_sgn = librosa.stft(test, n_fft=1024, hop_length=512)\n",
    "  test_s = np.abs(test_sgn)\n",
    "\n",
    "  pred = sess.run(logits, feed_dict={X: test_s.T})\n",
    "  pred = np.multiply(np.divide(test_sgn,test_s),pred.T)\n",
    "  sh_test = librosa.istft(pred, hop_length=512, length=len(test))\n",
    "  \n",
    "  \n",
    "  s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
    "  print(snr(s, sh_test))\n",
    "  outfile= \"train_s_recons.wav\"\n",
    "  librosa.output.write_wav(outfile, sh_test, sr)\n",
    "  return snr(s, sh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LZOabnKs_OXP",
    "outputId": "500a73e1-6fe9-405d-d313-383aae53aa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR for train sample :\n",
      "16.940776109695435\n"
     ]
    }
   ],
   "source": [
    "# process_test('test_x_01.wav',1)\n",
    "# process_test('test_x_02.wav',2)\n",
    "print('SNR for train sample :')\n",
    "snr = process_train('train_dirty_male.wav',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gL1edZ_Xw0Fz"
   },
   "outputs": [],
   "source": [
    "with open(\"performance.txt\", \"a\") as text_file:\n",
    "    print(f\"CNN 1\", file=text_file)\n",
    "    print(f\"SNR: {snr}\", file=text_file)\n",
    "#     print(f\"LR: {lr}\", file=text_file)\n",
    "    print(f\"LR: {lr}\\t Iterations: {n_iterations}\\t Batch Size: {batch_size}\", file=text_file)\n",
    "    print(f\"Filter1: {filter1}\\t Kernel1: {kernel_size1}\", file=text_file)\n",
    "    print(f\"Filter2: {filter2}\\t Kernel2: {kernel_size2}\", file=text_file)\n",
    "    print(f\"Dense neurons: {n_dense}\\t Drop out: {drop_out}\\n\", file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5z0BbnGgnvxM"
   },
   "source": [
    "** Result **\n",
    "* With given parameters for 1-d CNN the SNR for train file is 16.94. \\\n",
    "**SNR**: **16.940776109695435** \\\n",
    "**Learning Rate**: 0.001\t **Iterations**: 1000\t\\\n",
    "**Batch Size**: 128 \\\n",
    "**Filter1**: 32\t **Kernel1**: 3 \\\n",
    "**Filter2**: 64\t **Kernel2**: 2 \\\n",
    "**Dense neurons**: 2048\t \\\n",
    "Drop out: 0.4\n",
    "* The output files generated for test audio samples seem reasonable with less noise of chips but the performance did not seem as good as that of fully connected layer as far as audio is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_HW2_Q1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
