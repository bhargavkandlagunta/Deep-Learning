{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW4_Q1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CDZ_rlbivlcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ]
    },
    {
      "metadata": {
        "id": "WMCB83XvvoEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation and Architecture\n",
        "\n",
        "* Implemented a Siamese network to classify speaker voice.\n",
        "* RNN model with 2 GRU cells.\n",
        "* GRU\n",
        "   - units: 512\n",
        "   - dropout: 0.1\n",
        "* Batch Normalization\n",
        "* Dense Layer with 10 output units and relu activation\n",
        "* L2 normalization\n",
        "* Flattening layer\n",
        "* Take output for X_left, X_right and find innerproduct .\n",
        "* Apply sigmoid over the output inner product.\n",
        "* Loss - sigmoid cross entropy logits\n",
        "* Optimizer: Adam\n",
        "* Learning Rate: 0.0001\n",
        "\n",
        "## Conclusion\n",
        "* Tried different networks using LSTM cells, GRU cells, added batch,l2 normalization.\n",
        "* Accuracy on test set is not great.\n",
        "* Achieved accuracy around **$67\\%$**\n"
      ]
    },
    {
      "metadata": {
        "id": "817OmOI6N3hb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import wave, os, glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import itertools\n",
        "from random import randint\n",
        "from random import choice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGT9ENLVOcfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('hw4_trs.pkl', 'rb') as f:\n",
        "    train_s = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EnlP7jDNZT_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_stft(sgn):\n",
        "#   s, sr=librosa.load(filename, sr=None)\n",
        "  S_sgn=librosa.stft(sgn, n_fft=1024, hop_length=512)\n",
        "  S_sgn = np.abs(S_sgn).T\n",
        "#   S_sgn = np.abs(S_sgn)\n",
        "  return S_sgn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-L5yPX_R0Yp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_minibatch(train_s, speaker, size):\n",
        "  N = 10\n",
        "  L = size\n",
        "  sp_s = train_s[speaker*10: (speaker*10) + 10]\n",
        "  pos_minibatch = []\n",
        "  for x in range(L):\n",
        "    curr_sp_i = randint(0, N-1)\n",
        "    rest_sp_i = randint(0, N-1)\n",
        "#     print(curr_sp_i, rest_sp_i)\n",
        "    pos_minibatch.append([sp_s[curr_sp_i], sp_s[rest_sp_i]])\n",
        "#   list_pos = [[sp_s[i], sp_s[j]] for (i, j) in itertools.combinations(list(range(N)), 2)]\n",
        "#   pos_minibatch = list_pos[0:L]\n",
        "  neg_minibatch = []\n",
        "  for x in range(L):\n",
        "    curr_sp_i = randint(0, N-1)\n",
        "#     rest_sp_i = randint(N, len(train_s)-1)\n",
        "    numbers = list(range(0,speaker*N)) + list(range(speaker*N + 10,len(train_s)))\n",
        "    rest_sp_i = choice(numbers)\n",
        "#     print(curr_sp_i, rest_sp_i)\n",
        "    neg_minibatch.append([sp_s[curr_sp_i], train_s[rest_sp_i]])\n",
        "  minibatch = []\n",
        "  minibatch_left = []\n",
        "  minibatch_right = []\n",
        "  minibatch_out = []\n",
        "#   print(len(pos_minibatch))\n",
        "  for row_p in pos_minibatch:\n",
        "#     minibatch.append(row_p)\n",
        "    minibatch_left.append(np.array(row_p[0]))\n",
        "    minibatch_right.append(np.array(row_p[1]))\n",
        "    minibatch_out.append(np.array(1))\n",
        "  for row_n in neg_minibatch:\n",
        "#     minibatch.append(row_n)\n",
        "    minibatch_left.append(np.array(row_n[0]))\n",
        "    minibatch_right.append(np.array(row_n[1]))\n",
        "    minibatch_out.append(np.array(0))\n",
        "  return np.array(minibatch_left), np.array(minibatch_right), np.array(minibatch_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmhdpxPKZnxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stft(train_s):\n",
        "  train_stft = []\n",
        "  for sgn in train_s:\n",
        "    train_stft.append(get_stft(sgn))\n",
        "  return train_stft\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-R-eJrJobNcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stft = stft(train_s)\n",
        "# l,r,o = gen_minibatch(train_stft, 1, 6)\n",
        "l2, r2, o2 = gen_minibatch(train_stft, 2, 25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukTBcul3yqhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # print([t for t in r])\n",
        "\n",
        "# print('-------------')\n",
        "# print([t for t in r2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moGjgcmMbPoE",
        "colab_type": "code",
        "outputId": "3ee486fe-dc39-43be-8069-f05eec75196a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_s[0]))\n",
        "print((train_stft[11].shape))\n",
        "# print((sp1_mb[0][0].shape))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16180\n",
            "(32, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3HBJr9pqqx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ee140658-ecf8-48b1-9356-54d9bcc555d6"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "X_left = tf.placeholder(tf.float32, shape=(None, None, 513))\n",
        "X_right = tf.placeholder(tf.float32, shape=(None, None, 513))\n",
        "y_actual = tf.placeholder(tf.float32, shape=(None))\n",
        "dropout = tf.placeholder(tf.float32)\n",
        "train_phase = tf.placeholder(tf.bool)\n",
        "layers = []\n",
        "layer = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(512, \n",
        "                                                          kernel_initializer =tf.contrib.layers.variance_scaling_initializer()),\n",
        "                                                          output_keep_prob = dropout)\n",
        "# layer = tf.contrib.rnn.LSTMCell(513, forget_bias=1.0)\n",
        "# layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout)\n",
        "layers.append(layer)\n",
        "layer = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(512, \n",
        "                                                          kernel_initializer =tf.contrib.layers.variance_scaling_initializer()),\n",
        "                                                          output_keep_prob = dropout)\n",
        "# layer = tf.contrib.rnn.LSTMCell(513, forget_bias=1.0)\n",
        "# layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout)\n",
        "layers.append(layer)\n",
        "layer = tf.contrib.rnn.MultiRNNCell(layers)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-57-bfae724747b4>:9: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yzXyh60Wqsj9",
        "colab_type": "code",
        "outputId": "08542123-f3f7-4442-b5d7-9db95450f60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"model\") as scope:\n",
        "  out_left, _ = tf.nn.dynamic_rnn(layer, X_left, dtype=tf.float32)\n",
        "#   out_left    = tf.layers.batch_normalization(out_left)\n",
        "  out_left    = tf.layers.batch_normalization(\n",
        "        inputs=out_left,\n",
        "        axis=-1,\n",
        "        momentum=0.9,\n",
        "        epsilon=0.001,\n",
        "        center=True,\n",
        "        scale=True,\n",
        "        reuse= False,\n",
        "        training = train_phase)\n",
        "#   logits_left = tf.contrib.layers.fully_connected(out_left, 10, activation_fn=tf.nn.tanh)\n",
        "  logits_left = tf.layers.dense(out_left, 10, kernel_initializer= tf.contrib.layers.variance_scaling_initializer(),activation=tf.nn.tanh)\n",
        "  logits_left = tf.contrib.layers.flatten(logits_left)\n",
        "  logits_left = tf.nn.l2_normalize(logits_left, 0)\n",
        "with tf.variable_scope(scope, reuse=True):\n",
        "  out_right, _ = tf.nn.dynamic_rnn(layer, X_right, dtype=tf.float32)\n",
        "#   out_right    = tf.layers.batch_normalization(out_right)\n",
        "  out_right    = tf.layers.batch_normalization(\n",
        "        inputs=out_right,\n",
        "        axis=-1,\n",
        "        momentum=0.9,\n",
        "        epsilon=0.001,\n",
        "        center=True,\n",
        "        scale=True,\n",
        "        reuse= False,\n",
        "        training = train_phase)\n",
        "#   logits_right = tf.contrib.layers.fully_connected(out_right, 10, activation_fn=tf.nn.tanh)\n",
        "  logits_right = tf.layers.dense(out_right, 10, kernel_initializer= tf.contrib.layers.variance_scaling_initializer(),activation=tf.nn.tanh)\n",
        "  logits_right = tf.contrib.layers.flatten(logits_right)\n",
        "  logits_right = tf.nn.l2_normalize(logits_right, 0)\n",
        "  \n",
        "  \n",
        "print(logits_right.shape)  \n",
        "print(tf.multiply(logits_left,logits_right).shape)\n",
        "innerpd = tf.reduce_sum(tf.multiply(logits_left,logits_right), axis = 1, keepdims=True, name = 'innerpd')\n",
        "# innerpd = tf.reduce_sum(tf.multiply(tf.reshape(logits_left, [-1]),tf.reshape(logits_right, [-1])), axis = 1, keepdims=True, name = 'innerpd')\n",
        "# print(innerpd.shape)\n",
        "# innerpd = tf.reduce_sum(innerpd, 0)\n",
        "print(\"reshaped :\", innerpd.shape)\n",
        "\n",
        "sigmoid_out = tf.nn.sigmoid(innerpd,name = 'sigmoid_out')\n",
        "\n",
        "print(type(sigmoid_out))\n",
        "print(sigmoid_out.shape)\n",
        "# gradOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "# train = gradOptimizer.minimize(loss_siamese)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-58-4378b88af763>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "(?, ?)\n",
            "(?, ?)\n",
            "reshaped : (?, 1)\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "(?, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4L8ZwgvAxEaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# w = tf.reshape(logits_left, -1)\n",
        "# print(w.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVBx52vOqu0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss=tf.losses.mean_squared_error(labels=y_actual, predictions=logits)\n",
        "\n",
        "# train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXmcloYIsIwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss  = tf.reduce_sum(-(y_actual)*tf.log(sigmoid_out+ (10**-6)) - (1 - y_actual) * tf.log(1 - sigmoid_out + (10**-6)))\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels= y_actual , logits= sigmoid_out))\n",
        "# loss = -(y_actual)*tf.log(sigmoid_out+ (10**-6)) - (1 - y_actual) * tf.log(1 - sigmoid_out + (10**-6))\n",
        "train_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
        "\n",
        "correct_pred = tf.equal(sigmoid_out, y_actual)\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(sigmoid_out),y_actual),tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ah9E0J18rXZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOG_DIR = '/tmp/log'\n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR)\n",
        "# )\n",
        "# # ! curl http://localhost:6006\n",
        "\n",
        "# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-386.zip\n",
        "# ! unzip ngrok-stable-windows-386.zip\n",
        "\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYOVIw9Dqwsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "saver=tf.train.Saver()\n",
        "sess.run(init)\n",
        "# train_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DIBKYzevqzHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_l = 50\n",
        "left = []\n",
        "right = []\n",
        "out = []\n",
        "for epoch in range(10):\n",
        "  loss_print = 0\n",
        "  for i in range(0,50):\n",
        "    left, right, out = gen_minibatch(train_stft, i, batch_l)\n",
        "    loss1, t, inpd, lef, rig = sess.run([loss, train_step, innerpd,logits_left, logits_right], {X_left: left, X_right: right, y_actual: out, dropout: 0.9, train_phase: True})\n",
        "#     print('Inner product :', inpd)\n",
        "#     print('Left ', lef[0].shape)\n",
        "#     print('Right', rig.shape)\n",
        "#     print(loss1)\n",
        "  loss_print += loss1\n",
        "#   print('Loss at epoch',epoch+1, 'is: ', loss_print)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FmizqD4qz_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Phase"
      ]
    },
    {
      "metadata": {
        "id": "akE4o6FB3ks8",
        "colab_type": "code",
        "outputId": "74ab0b5f-19e5-4bce-a6e6-a5244230b082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# print([x.name for x in tf.global_variables()])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/bias:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/kernel:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/bias:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/kernel:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/bias:0', 'model/batch_normalization/gamma:0', 'model/batch_normalization/beta:0', 'model/batch_normalization/moving_mean:0', 'model/batch_normalization/moving_variance:0', 'model/dense/kernel:0', 'model/dense/bias:0', 'beta1_power:0', 'beta2_power:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/gates/bias/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/gru_cell/candidate/bias/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/gates/bias/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/gru_cell/candidate/bias/Adam_1:0', 'model/batch_normalization/gamma/Adam:0', 'model/batch_normalization/gamma/Adam_1:0', 'model/batch_normalization/beta/Adam:0', 'model/batch_normalization/beta/Adam_1:0', 'model/dense/kernel/Adam:0', 'model/dense/kernel/Adam_1:0', 'model/dense/bias/Adam:0', 'model/dense/bias/Adam_1:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pePTS9T8UPi9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# l = [z for z in left]\n",
        "# print(l[0][0,0])\n",
        "# r = [y for y in right]\n",
        "# print(r)\n",
        "\n",
        "# print(sum(out==1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ED-xwUFQ3uEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "['model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0', 'model/fully_connected/weights:0', 'model/fully_connected/biases:0', 'beta1_power:0', 'beta2_power:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1:0', 'model/fully_connected/weights/Adam:0', 'model/fully_connected/weights/Adam_1:0', 'model/fully_connected/biases/Adam:0', 'model/fully_connected/biases/Adam_1:0']"
      ]
    },
    {
      "metadata": {
        "id": "jATPHG5U5AKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "['model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0', 'model/fully_connected/weights:0', 'model/fully_connected/biases:0', 'model/fully_connected_1/weights:0', 'model/fully_connected_1/biases:0', 'beta1_power:0', 'beta2_power:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam:0', 'model/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1:0', 'model/fully_connected/weights/Adam:0', 'model/fully_connected/weights/Adam_1:0', 'model/fully_connected/biases/Adam:0', 'model/fully_connected/biases/Adam_1:0', 'model/fully_connected_1/weights/Adam:0', 'model/fully_connected_1/weights/Adam_1:0', 'model/fully_connected_1/biases/Adam:0', 'model/fully_connected_1/biases/Adam_1:0']"
      ]
    },
    {
      "metadata": {
        "id": "oGUlDiFYlcK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Test phase\n",
        "\n",
        "with open('hw4_tes.pkl', 'rb') as f:\n",
        "    test_s = pickle.load(f)\n",
        "    \n",
        "test_stft = stft(test_s)  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNutpx5Kl5JH",
        "colab_type": "code",
        "outputId": "04c37146-0f45-4639-b8e8-03658009a96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "l2, r2, o2 = gen_minibatch(train_stft, 2, 25)\n",
        "# print(l2)\n",
        "acc = 0\n",
        "for i in range(0,20):\n",
        "  l,r,o = gen_minibatch(test_stft, i, 20)\n",
        "  test_accuracy,s_out = sess.run([accuracy,sigmoid_out], feed_dict={X_left: l, X_right:r, y_actual: o, dropout:1.0, train_phase: False}) \n",
        "  acc_t = sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.reshape(s_out, [-1])),o),tf.float32)))\n",
        "#   print(acc_t)\n",
        "  acc += acc_t\n",
        "  \n",
        "acc_final = acc/(20)  \n",
        "print('\\nAccuracy on test set:', acc_final)\n",
        "# test_accuracy = sess.run(sigmoid_out, feed_dict={X_left: l2, X_right:r2, y_actual: o2, dropout:1.0})\n",
        "# print(\"\\nAccuracy on test set:\", test_accuracy)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on test set: 0.672\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}